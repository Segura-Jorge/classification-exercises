{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2d24834a-1187-464a-a31a-0240f2e8eab0",
   "metadata": {},
   "source": [
    "#### 1. Fit the Random Forest classifier to your training sample and transform (i.e. make predictions on the training sample) setting the random_state accordingly and setting min_samples_leaf = 1 and max_depth = 10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f4a99fc-2302-43fc-9da2-d9bc0482c6c5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d3fc353e-3cc9-4118-845d-029edfb55f74",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### 2. Evaluate your results using the model score, confusion matrix, and classification report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "719f887d-2229-43fd-91cc-37e001c6f84e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "23ae4ae8-7637-4d18-b73c-18bd8f643433",
   "metadata": {},
   "source": [
    "#### 3. Print and clearly label the following: Accuracy, true positive rate, false positive rate, true negative rate, false negative rate, precision, recall, f1-score, and support."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "061c13ba-7765-4785-91ca-632391e11927",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d0660f10-411a-48dd-bd6c-e01957e32968",
   "metadata": {},
   "source": [
    "#### 4. Run through steps increasing your min_samples_leaf and decreasing your max_depth."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d398adac-202a-4bb2-904f-3b4578afa678",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3353501a-d7ec-4cbd-a259-11125b836f8e",
   "metadata": {},
   "source": [
    "#### 5. What are the differences in the evaluation metrics? Which performs better on your in-sample data? Why?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a526f0e0-d2d3-47fe-a55a-e26b73298179",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "49249676-e5c7-4f21-b9fc-d40464615ddd",
   "metadata": {},
   "source": [
    "#### After making a few models, which one has the best performance (or closest metrics) on both train and validate?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8d946e5-7930-4d7c-8b9f-3609ff46c3a7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
